{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4de55f3d-0350-4206-b2f6-26ed47e15d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF vectorizer loaded successfully.\n",
      "Emotion model loaded successfully.\n",
      "Gender model and scaler loaded successfully.\n",
      "Language model loaded successfully.\n",
      "Error loading language model: Loaded language model does not have a predict method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harsh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from keras.models import load_model\n",
    "import speech_recognition as sr\n",
    "import pickle\n",
    "\n",
    "# Define the relative paths to the trained models\n",
    "base_dir = os.getcwd()  # Get the current working directory\n",
    "\n",
    "emotion_model_path = os.path.join(base_dir, '..', 'saved models', 'Emotion_speech', 'emotion_speech_task4.model')\n",
    "gender_model_path = os.path.join(base_dir, '..', 'saved models', 'Voice_gender_model', 'rfc_model_voice_gender_task4.joblib')\n",
    "scaler_path = os.path.join(base_dir, '..', 'saved models', 'Voice_gender_model', 'scaler.joblib')\n",
    "language_model_path = os.path.join(base_dir, '..', 'saved models', 'Language_detection_model', 'language_detection_rf_model.pkl')\n",
    "tfidf_vectorizer_path = os.path.join(base_dir, '..', 'saved models', 'Language_detection_model', 'tfidf_vectorizer.pkl')\n",
    "\n",
    "\n",
    "# Load the models and vectorizer\n",
    "try:\n",
    "    tfidf_vectorizer = joblib.load(tfidf_vectorizer_path)\n",
    "    print(\"TF-IDF vectorizer loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading TF-IDF vectorizer: {e}\")\n",
    "\n",
    "try:\n",
    "    emotion_model = load_model(emotion_model_path)\n",
    "    print(\"Emotion model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading emotion model: {e}\")\n",
    "\n",
    "try:\n",
    "    gender_model = joblib.load(gender_model_path)\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    print(\"Gender model and scaler loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading gender model or scaler: {e}\")\n",
    "\n",
    "try:\n",
    "    with open(language_model_path, 'rb') as f:\n",
    "        language_model = pickle.load(f)\n",
    "    print(\"Language model loaded successfully.\")\n",
    "    # Check if the loaded model has a predict method\n",
    "    if not hasattr(language_model, 'predict'):\n",
    "        raise ValueError(\"Loaded language model does not have a predict method\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading language model: {e}\")\n",
    "\n",
    "# Emotion labels\n",
    "emotion_labels = {\n",
    "    0: 'neutral',\n",
    "    1: 'calm',\n",
    "    2: 'happy',\n",
    "    3: 'sad',\n",
    "    4: 'angry',\n",
    "    5: 'fearful',\n",
    "    6: 'disgust',\n",
    "    7: 'surprised'\n",
    "}\n",
    "\n",
    "def preprocess_audio(audio_path):\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    mfccs = np.mean(mfccs.T, axis=0)\n",
    "    mfccs = mfccs.reshape(1, -1)\n",
    "    return mfccs, y, sr\n",
    "\n",
    "def predict_gender(audio_features):\n",
    "    if audio_features.shape[1] != 20:\n",
    "        raise ValueError(f\"Expected 20 MFCC features, got {audio_features.shape[1]}\")\n",
    "    scaled_features = scaler.transform(audio_features)\n",
    "    prediction = gender_model.predict(scaled_features)\n",
    "    return 'female' if prediction[0] == 0 else 'male'\n",
    "\n",
    "def convert_audio_to_text(audio_data, sample_rate):\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio = sr.AudioData(audio_data.tobytes(), sample_rate, 2)\n",
    "    try:\n",
    "        print(\"Attempting speech recognition...\")\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(f\"Recognized text: {text}\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Speech recognition could not understand audio\")\n",
    "        return \"Speech recognition could not understand audio\"\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "        return f\"Could not request results from Google Speech Recognition service; {e}\"\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during speech recognition: {e}\")\n",
    "        return f\"An error occurred during speech recognition: {e}\"\n",
    "\n",
    "def predict_language(audio_path):\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    print(f\"Audio data shape: {y.shape}, Sample rate: {sr}\")\n",
    "    text_data = convert_audio_to_text(y, sr)\n",
    "    print(f\"Converted audio to text: {text_data}\")\n",
    "    if not text_data or \"Speech recognition could not understand audio\" in text_data:\n",
    "        return \"Unable to determine language from audio\"\n",
    "    prediction = predict_language_from_text(text_data)\n",
    "    return prediction\n",
    "\n",
    "def predict_language_from_text(text_data):\n",
    "    text_features = tfidf_vectorizer.transform([text_data])\n",
    "    prediction = language_model.predict(text_features)\n",
    "    return prediction[0]\n",
    "\n",
    "def predict_emotion(audio_features):\n",
    "    prediction = emotion_model.predict(audio_features)\n",
    "    return emotion_labels[np.argmax(prediction)]\n",
    "\n",
    "def process_audio(file_path):\n",
    "    audio_features, y, sr = preprocess_audio(file_path)\n",
    "\n",
    "    gender = predict_gender(audio_features)\n",
    "    if gender != 'female':\n",
    "        return \"Please upload a female voice.\"\n",
    "\n",
    "    language = predict_language(file_path)\n",
    "    if language != 'English':\n",
    "        return \"Please upload an English language voice.\"\n",
    "\n",
    "    emotion = predict_emotion(audio_features)\n",
    "    return f\"The detected emotion is: {emotion}\"\n",
    "\n",
    "def upload_file():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Audio Files\", \"*.wav *.mp3\")])\n",
    "    if file_path:\n",
    "        result = process_audio(file_path)\n",
    "        messagebox.showinfo(\"Result\", result)\n",
    "\n",
    "# GUI Setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Emotion Detection from Audio\")\n",
    "\n",
    "upload_button = tk.Button(root, text=\"Upload Audio File\", command=upload_file)\n",
    "upload_button.pack(pady=20)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299e7325-7d2f-4441-876f-5cbae950ab2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
